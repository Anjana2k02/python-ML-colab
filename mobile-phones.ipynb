{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/i/BzYh+QFM536jtbe9jR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475},"id":"A6MGc9bpfFkA","executionInfo":{"status":"ok","timestamp":1721367658113,"user_tz":-330,"elapsed":401,"user":{"displayName":"Anjana Indunil","userId":"00547315779733882880"}},"outputId":"099dcdf4-f415-42a2-ad7b-14520a47b851"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n","0             842     0          2.2         0   1       0           7    0.6   \n","1            1021     1          0.5         1   0       1          53    0.7   \n","2             563     1          0.5         1   2       1          41    0.9   \n","3             615     1          2.5         0   0       0          10    0.8   \n","4            1821     1          1.2         0  13       1          44    0.6   \n","5            1859     0          0.5         1   3       0          22    0.7   \n","6            1821     0          1.7         0   4       1          10    0.8   \n","7            1954     0          0.5         1   0       0          24    0.8   \n","8            1445     1          0.5         0   0       0          53    0.7   \n","9             509     1          0.6         1   2       1           9    0.1   \n","10            769     1          2.9         1   0       0           9    0.1   \n","11           1520     1          2.2         0   5       1          33    0.5   \n","\n","    mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n","0         188        2  ...         20       756  2549     9     7         19   \n","1         136        3  ...        905      1988  2631    17     3          7   \n","2         145        5  ...       1263      1716  2603    11     2          9   \n","3         131        6  ...       1216      1786  2769    16     8         11   \n","4         141        2  ...       1208      1212  1411     8     2         15   \n","5         164        1  ...       1004      1654  1067    17     1         10   \n","6         139        8  ...        381      1018  3220    13     8         18   \n","7         187        4  ...        512      1149   700    16     3          5   \n","8         174        7  ...        386       836  1099    17     1         20   \n","9          93        5  ...       1137      1224   513    19    10         12   \n","10        182        5  ...        248       874  3946     5     2          7   \n","11        177        8  ...        151      1005  3826    14     9         13   \n","\n","    three_g  touch_screen  wifi  price_range  \n","0         0             0     1            1  \n","1         1             1     0            0  \n","2         1             1     0            0  \n","3         1             0     0            0  \n","4         1             1     0            1  \n","5         1             0     0            1  \n","6         1             0     1            1  \n","7         1             1     1            0  \n","8         1             0     0            0  \n","9         1             0     0            0  \n","10        0             0     0            1  \n","11        1             1     1            1  \n","\n","[12 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-5ff10407-8992-4792-865a-fcfa582ff782\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>battery_power</th>\n","      <th>blue</th>\n","      <th>clock_speed</th>\n","      <th>dual_sim</th>\n","      <th>fc</th>\n","      <th>four_g</th>\n","      <th>int_memory</th>\n","      <th>m_dep</th>\n","      <th>mobile_wt</th>\n","      <th>n_cores</th>\n","      <th>...</th>\n","      <th>px_height</th>\n","      <th>px_width</th>\n","      <th>ram</th>\n","      <th>sc_h</th>\n","      <th>sc_w</th>\n","      <th>talk_time</th>\n","      <th>three_g</th>\n","      <th>touch_screen</th>\n","      <th>wifi</th>\n","      <th>price_range</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842</td>\n","      <td>0</td>\n","      <td>2.2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0.6</td>\n","      <td>188</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>20</td>\n","      <td>756</td>\n","      <td>2549</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1021</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>53</td>\n","      <td>0.7</td>\n","      <td>136</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>905</td>\n","      <td>1988</td>\n","      <td>2631</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>563</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>41</td>\n","      <td>0.9</td>\n","      <td>145</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>1263</td>\n","      <td>1716</td>\n","      <td>2603</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>615</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0.8</td>\n","      <td>131</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>1216</td>\n","      <td>1786</td>\n","      <td>2769</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1821</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>0.6</td>\n","      <td>141</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1208</td>\n","      <td>1212</td>\n","      <td>1411</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1859</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0.7</td>\n","      <td>164</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1004</td>\n","      <td>1654</td>\n","      <td>1067</td>\n","      <td>17</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1821</td>\n","      <td>0</td>\n","      <td>1.7</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0.8</td>\n","      <td>139</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>381</td>\n","      <td>1018</td>\n","      <td>3220</td>\n","      <td>13</td>\n","      <td>8</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1954</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24</td>\n","      <td>0.8</td>\n","      <td>187</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>512</td>\n","      <td>1149</td>\n","      <td>700</td>\n","      <td>16</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1445</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.7</td>\n","      <td>174</td>\n","      <td>7</td>\n","      <td>...</td>\n","      <td>386</td>\n","      <td>836</td>\n","      <td>1099</td>\n","      <td>17</td>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>509</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0.1</td>\n","      <td>93</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>1137</td>\n","      <td>1224</td>\n","      <td>513</td>\n","      <td>19</td>\n","      <td>10</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>769</td>\n","      <td>1</td>\n","      <td>2.9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0.1</td>\n","      <td>182</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>248</td>\n","      <td>874</td>\n","      <td>3946</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>2.2</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>33</td>\n","      <td>0.5</td>\n","      <td>177</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>151</td>\n","      <td>1005</td>\n","      <td>3826</td>\n","      <td>14</td>\n","      <td>9</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12 rows × 21 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ff10407-8992-4792-865a-fcfa582ff782')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5ff10407-8992-4792-865a-fcfa582ff782 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5ff10407-8992-4792-865a-fcfa582ff782');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8e9f8ab1-0b6f-4a81-a703-87e3d84ccea9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e9f8ab1-0b6f-4a81-a703-87e3d84ccea9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8e9f8ab1-0b6f-4a81-a703-87e3d84ccea9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}],"source":["import pandas as pn\n","\n","url = \"https://raw.githubusercontent.com/Anjana2k02/Dataset/main/Mobile_Price_Classification-220531-204702.csv\"\n","\n","df = pn.read_csv(url)\n","df.head(12)"]},{"cell_type":"markdown","source":["#Avoid dependencies"],"metadata":{"id":"8CeK6HBOgl8f"}},{"cell_type":"code","source":["x=df.drop('price_range',axis=1)\n","y=df['price_range']\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tk9h9x9Ag3Vg","executionInfo":{"status":"ok","timestamp":1721367790808,"user_tz":-330,"elapsed":382,"user":{"displayName":"Anjana Indunil","userId":"00547315779733882880"}},"outputId":"f4d92af2-ff24-4df1-f23d-76a8ca4795cd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["0       1\n","1       0\n","2       0\n","3       0\n","4       1\n","       ..\n","1995    0\n","1996    0\n","1997    1\n","1998    0\n","1999    1\n","Name: price_range, Length: 2000, dtype: int64\n"]}]},{"cell_type":"markdown","source":["#Train Model"],"metadata":{"id":"hVieDN4QhGdj"}},{"cell_type":"code","source":["#import dependencies\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import numpy as np\n","\n","#Load Dataset\n","url = \"https://raw.githubusercontent.com/Anjana2k02/Dataset/main/Mobile_Price_Classification-220531-204702.csv\"\n","df = pd.read_csv(url)\n","\n","#Define features and target\n","x = df.drop('price_range', axis=1)\n","y = df['price_range']\n","\n","#Split data set into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=0)\n","\n","#Standardize the Features\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","\n","#Build the model\n","model = Sequential()\n","model.add(Dense(units=8, activation='relu', input_dim=20))\n","model.add(Dense(units=4, activation='relu'))\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","#Get the summary\n","model.summary()\n","\n","#Compile the model\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","#Train the model\n","model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test))\n","\n","#save the model weights\n","model.save_weights('model_weights.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hUpL0TOfhKJq","executionInfo":{"status":"ok","timestamp":1721369721242,"user_tz":-330,"elapsed":23552,"user":{"displayName":"Anjana Indunil","userId":"00547315779733882880"}},"outputId":"dd13d9ab-4707-4fb3-94a2-361162805d2d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 8)                 168       \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 36        \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 5         \n","                                                                 \n","=================================================================\n","Total params: 209 (836.00 Byte)\n","Trainable params: 209 (836.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/100\n","47/47 [==============================] - 2s 7ms/step - loss: 0.6951 - accuracy: 0.5320 - val_loss: 0.6794 - val_accuracy: 0.5300\n","Epoch 2/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5727 - val_loss: 0.6687 - val_accuracy: 0.5640\n","Epoch 3/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5907 - val_loss: 0.6586 - val_accuracy: 0.5880\n","Epoch 4/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6113 - val_loss: 0.6485 - val_accuracy: 0.6100\n","Epoch 5/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6267 - val_loss: 0.6389 - val_accuracy: 0.6140\n","Epoch 6/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6360 - val_loss: 0.6285 - val_accuracy: 0.6260\n","Epoch 7/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6387 - val_loss: 0.6186 - val_accuracy: 0.6300\n","Epoch 8/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6387 - val_loss: 0.6119 - val_accuracy: 0.6440\n","Epoch 9/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6407 - val_loss: 0.6056 - val_accuracy: 0.6420\n","Epoch 10/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6447 - val_loss: 0.6000 - val_accuracy: 0.6460\n","Epoch 11/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6453 - val_loss: 0.5956 - val_accuracy: 0.6480\n","Epoch 12/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6473 - val_loss: 0.5928 - val_accuracy: 0.6500\n","Epoch 13/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6467 - val_loss: 0.5908 - val_accuracy: 0.6480\n","Epoch 14/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6447 - val_loss: 0.5891 - val_accuracy: 0.6420\n","Epoch 15/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.6473 - val_loss: 0.5888 - val_accuracy: 0.6460\n","Epoch 16/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6500 - val_loss: 0.5871 - val_accuracy: 0.6380\n","Epoch 17/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6473 - val_loss: 0.5866 - val_accuracy: 0.6360\n","Epoch 18/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.6560 - val_loss: 0.5851 - val_accuracy: 0.6400\n","Epoch 19/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6540 - val_loss: 0.5847 - val_accuracy: 0.6380\n","Epoch 20/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6580 - val_loss: 0.5837 - val_accuracy: 0.6380\n","Epoch 21/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.6560 - val_loss: 0.5833 - val_accuracy: 0.6380\n","Epoch 22/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.6573 - val_loss: 0.5831 - val_accuracy: 0.6420\n","Epoch 23/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6627 - val_loss: 0.5835 - val_accuracy: 0.6440\n","Epoch 24/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.6607 - val_loss: 0.5826 - val_accuracy: 0.6420\n","Epoch 25/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6687 - val_loss: 0.5831 - val_accuracy: 0.6420\n","Epoch 26/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.6620 - val_loss: 0.5831 - val_accuracy: 0.6440\n","Epoch 27/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.6687 - val_loss: 0.5828 - val_accuracy: 0.6540\n","Epoch 28/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.6673 - val_loss: 0.5821 - val_accuracy: 0.6460\n","Epoch 29/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.6673 - val_loss: 0.5824 - val_accuracy: 0.6480\n","Epoch 30/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.6680 - val_loss: 0.5825 - val_accuracy: 0.6460\n","Epoch 31/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.6647 - val_loss: 0.5830 - val_accuracy: 0.6480\n","Epoch 32/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6713 - val_loss: 0.5828 - val_accuracy: 0.6500\n","Epoch 33/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.6680 - val_loss: 0.5831 - val_accuracy: 0.6480\n","Epoch 34/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.6687 - val_loss: 0.5835 - val_accuracy: 0.6520\n","Epoch 35/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.6727 - val_loss: 0.5834 - val_accuracy: 0.6480\n","Epoch 36/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.6720 - val_loss: 0.5833 - val_accuracy: 0.6480\n","Epoch 37/100\n","47/47 [==============================] - 1s 14ms/step - loss: 0.5588 - accuracy: 0.6727 - val_loss: 0.5828 - val_accuracy: 0.6500\n","Epoch 38/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.6807 - val_loss: 0.5830 - val_accuracy: 0.6520\n","Epoch 39/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.6713 - val_loss: 0.5833 - val_accuracy: 0.6480\n","Epoch 40/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.6753 - val_loss: 0.5839 - val_accuracy: 0.6440\n","Epoch 41/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.6773 - val_loss: 0.5835 - val_accuracy: 0.6440\n","Epoch 42/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.6833 - val_loss: 0.5847 - val_accuracy: 0.6500\n","Epoch 43/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.6800 - val_loss: 0.5855 - val_accuracy: 0.6460\n","Epoch 44/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.6813 - val_loss: 0.5858 - val_accuracy: 0.6420\n","Epoch 45/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.6880 - val_loss: 0.5850 - val_accuracy: 0.6520\n","Epoch 46/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.6867 - val_loss: 0.5854 - val_accuracy: 0.6500\n","Epoch 47/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.6867 - val_loss: 0.5864 - val_accuracy: 0.6480\n","Epoch 48/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.6900 - val_loss: 0.5866 - val_accuracy: 0.6520\n","Epoch 49/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.6893 - val_loss: 0.5864 - val_accuracy: 0.6480\n","Epoch 50/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.6933 - val_loss: 0.5879 - val_accuracy: 0.6460\n","Epoch 51/100\n","47/47 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.6920 - val_loss: 0.5881 - val_accuracy: 0.6480\n","Epoch 52/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.6933 - val_loss: 0.5884 - val_accuracy: 0.6460\n","Epoch 53/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.6953 - val_loss: 0.5887 - val_accuracy: 0.6540\n","Epoch 54/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.6980 - val_loss: 0.5894 - val_accuracy: 0.6480\n","Epoch 55/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.6920 - val_loss: 0.5899 - val_accuracy: 0.6400\n","Epoch 56/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.6940 - val_loss: 0.5899 - val_accuracy: 0.6460\n","Epoch 57/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.6953 - val_loss: 0.5907 - val_accuracy: 0.6440\n","Epoch 58/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.6980 - val_loss: 0.5901 - val_accuracy: 0.6460\n","Epoch 59/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.6960 - val_loss: 0.5909 - val_accuracy: 0.6460\n","Epoch 60/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.6940 - val_loss: 0.5918 - val_accuracy: 0.6460\n","Epoch 61/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.6987 - val_loss: 0.5932 - val_accuracy: 0.6420\n","Epoch 62/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.6900 - val_loss: 0.5924 - val_accuracy: 0.6400\n","Epoch 63/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.6960 - val_loss: 0.5946 - val_accuracy: 0.6380\n","Epoch 64/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.6933 - val_loss: 0.5932 - val_accuracy: 0.6400\n","Epoch 65/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.6987 - val_loss: 0.5944 - val_accuracy: 0.6400\n","Epoch 66/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.6927 - val_loss: 0.5949 - val_accuracy: 0.6420\n","Epoch 67/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.6967 - val_loss: 0.5952 - val_accuracy: 0.6380\n","Epoch 68/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.6980 - val_loss: 0.5964 - val_accuracy: 0.6380\n","Epoch 69/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.6980 - val_loss: 0.5969 - val_accuracy: 0.6320\n","Epoch 70/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.6987 - val_loss: 0.5965 - val_accuracy: 0.6360\n","Epoch 71/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.6940 - val_loss: 0.5983 - val_accuracy: 0.6380\n","Epoch 72/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.6967 - val_loss: 0.5999 - val_accuracy: 0.6400\n","Epoch 73/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.6960 - val_loss: 0.6009 - val_accuracy: 0.6420\n","Epoch 74/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7000 - val_loss: 0.6019 - val_accuracy: 0.6480\n","Epoch 75/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.6987 - val_loss: 0.6010 - val_accuracy: 0.6400\n","Epoch 76/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7007 - val_loss: 0.6013 - val_accuracy: 0.6420\n","Epoch 77/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7013 - val_loss: 0.6021 - val_accuracy: 0.6460\n","Epoch 78/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7033 - val_loss: 0.6036 - val_accuracy: 0.6320\n","Epoch 79/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7047 - val_loss: 0.6046 - val_accuracy: 0.6340\n","Epoch 80/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7000 - val_loss: 0.6048 - val_accuracy: 0.6400\n","Epoch 81/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7047 - val_loss: 0.6076 - val_accuracy: 0.6420\n","Epoch 82/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7087 - val_loss: 0.6056 - val_accuracy: 0.6400\n","Epoch 83/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7047 - val_loss: 0.6080 - val_accuracy: 0.6400\n","Epoch 84/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7080 - val_loss: 0.6086 - val_accuracy: 0.6420\n","Epoch 85/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7060 - val_loss: 0.6083 - val_accuracy: 0.6420\n","Epoch 86/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7027 - val_loss: 0.6098 - val_accuracy: 0.6460\n","Epoch 87/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7080 - val_loss: 0.6100 - val_accuracy: 0.6500\n","Epoch 88/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7060 - val_loss: 0.6116 - val_accuracy: 0.6480\n","Epoch 89/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7100 - val_loss: 0.6097 - val_accuracy: 0.6520\n","Epoch 90/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7080 - val_loss: 0.6108 - val_accuracy: 0.6520\n","Epoch 91/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7067 - val_loss: 0.6129 - val_accuracy: 0.6480\n","Epoch 92/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7093 - val_loss: 0.6134 - val_accuracy: 0.6480\n","Epoch 93/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7093 - val_loss: 0.6136 - val_accuracy: 0.6500\n","Epoch 94/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7100 - val_loss: 0.6137 - val_accuracy: 0.6520\n","Epoch 95/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7060 - val_loss: 0.6122 - val_accuracy: 0.6500\n","Epoch 96/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7060 - val_loss: 0.6149 - val_accuracy: 0.6580\n","Epoch 97/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7033 - val_loss: 0.6128 - val_accuracy: 0.6540\n","Epoch 98/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7067 - val_loss: 0.6150 - val_accuracy: 0.6520\n","Epoch 99/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7093 - val_loss: 0.6135 - val_accuracy: 0.6540\n","Epoch 100/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7080 - val_loss: 0.6153 - val_accuracy: 0.6560\n"]}]}]}